[{"path":"http://nickreich.github.io/coarseDataTools/articles/CFR_vignette.html","id":"introduction-to-the-data","dir":"Articles","previous_headings":"","what":"Introduction to the data","title":"Using outbreak data to estimate the relative case fatality ratio","text":"goal vignette provide tutorial implementing case fatality ratio estimation methods available coarseDataTools R package. illustrate methods, estimate relative case fatality ratio simulated outbreak dataset.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/articles/CFR_vignette.html","id":"loading-the-data-and-the-code","dir":"Articles","previous_headings":"","what":"Loading the data and the code","title":"Using outbreak data to estimate the relative case fatality ratio","text":"begin loading package set simulated data. data loaded simulated dataset five columns. Let’s take peek dataset. rows index observations particular time group. columns defined follows: time = specified unit time, \\(t\\), observation grp = covariate group, \\(j\\), observation R = number recovered cases observed D = number dead cases observed N = total number cases observed, D + R must perform little bit pre-processing data ready analysis. Specifically, need define \\(T\\) time periods want use analysis. avoid (moment) convergence issues associated small sample sizes, include times groups least 10 total cases observed. look new data matrix, can see new variable ’ve made used analysis:","code":"library(coarseDataTools) data(simulated.outbreak.deaths) simulated.outbreak.deaths[15:20, ] ##    time grp    R D    N ## 15   15   1   53 0   53 ## 16   16   1  121 0  121 ## 17   17   1  293 0  293 ## 18   18   1  731 0  731 ## 19   19   1 1613 0 1613 ## 20   20   1 3400 0 3400 ## set minimum number of observed cases for inclusion min.cases <- 10  ## observed cases N.1 <- simulated.outbreak.deaths[1:60, \"N\"] N.2 <- simulated.outbreak.deaths[61:120, \"N\"]  ## subset to run analyis on times with greater than min.cases first.t <- min(which(N.1 > min.cases & N.2 > min.cases)) last.t <- max(which(N.1 > min.cases & N.2 > min.cases)) idx.for.Estep <- first.t:last.t  ## find and label the subset of times to be used for estimation routine new.times <- seq_along(idx.for.Estep) simulated.outbreak.deaths <- cbind(simulated.outbreak.deaths, new.times = NA) simulated.outbreak.deaths[c(idx.for.Estep, idx.for.Estep + 60), \"new.times\"] <- rep(new.times, 2) simulated.outbreak.deaths[15:20, ] ##    time grp    R D    N new.times ## 15   15   1   53 0   53        NA ## 16   16   1  121 0  121        NA ## 17   17   1  293 0  293         1 ## 18   18   1  731 0  731         2 ## 19   19   1 1613 0 1613         3 ## 20   20   1 3400 0 3400         4"},{"path":"http://nickreich.github.io/coarseDataTools/articles/CFR_vignette.html","id":"running-an-analysis","dir":"Articles","previous_headings":"","what":"Running an analysis","title":"Using outbreak data to estimate the relative case fatality ratio","text":"wish fit model simulated dataset adjusts changing reporting rates time lag disease onset death. assume reporting rates dead recovered cases vary time covariate \\(j\\). also assume case fatality ratio vary time different \\(j\\) covariate groups. model formula adjusts reporting rates lag \\[\\begin{eqnarray} \\log E (D_{tj}) &=& \\log N_{tj} + \\beta_0 + \\alpha_t\\cdot X_t + \\gamma_j\\cdot Y_j \\end{eqnarray}\\] \\(X_t\\) \\(Y_j\\) indicator variables \\(t=2,\\dots,T\\) \\(j=2, \\dots,J\\). , \\(\\gamma_j\\) log relative case fatality ratio. EM algorithm described main paper imputes values \\(D_{tj}\\) E-step uses equation M-step. running analysis, need fix parameters. Specifically, need fix assumed \\(\\eta\\), vector probabilities define survival distribution. assume (0, .3, .4, .3). example, given case end dying, 40% chance death occur third day disease onset. Also, need set starting values \\(\\alpha\\) parameters model. assume \\(\\alpha_t=0\\) \\(t\\). set required. can now call central function, \\(\\tt{EMforCFR()}\\), generates three estimates CFR: na\"ive, reporting-rate-adjusted lag-adjusted estimators. [Note running cfr.ests generate warnings (many , likely) worry due fact likelihood uses non-integer outcomes calculating Poisson density function. expected behavior indication problem routine.] function \\(\\tt{EMforCFR()}\\) returns list following components: naive.rel.cfr = na\"ive estimator relative CFR glm.rel.cfr = reporting-rate-adjusted estimator relative CFR EM.rel.cfr = lag-adjusted estimator relative CFR EM.rel.cfr.var = variance log-scale lag-adjusted estimator taken final M-step EM.rel.cfr.var.SEM = Supplemented EM algorithm variance log-scale lag-adjusted estimator EM.rel.cfr.chain = vector EM algorithm iterates lag-adjusted relative CFR estimates ests = coefficient estimates model ests.chain.EM = matrix coefficient estimates, EM iteration DM = DM matrix SEM algorithm DMiter = vector showing many iterations took variance component converge SEM algorithm particularly interested following components:","code":"assumed.nu <- c(0, 0.3, 0.4, 0.3) alpha.start <- rep(0, 22) cfr.ests <- EMforCFR(   assumed.nu = assumed.nu,   alpha.start.values = alpha.start, full.data = simulated.outbreak.deaths, verb = FALSE,   SEM.var = TRUE, max.iter = 100, tol = 1e-5 ) cfr.ests$naive.rel.cfr ## [1] 1.11048 cfr.ests$glm.rel.cfr ## factor(dat[, \"grp\"])2  ##            0.06035187 cfr.ests$EM.rel.cfr ## [1] 0.3370229 cfr.ests$EM.rel.cfr.var.SEM ## [1] 0.008047843"},{"path":"http://nickreich.github.io/coarseDataTools/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nicholas G. Reich. Author, maintainer. Justin Lessler. Author. Andrew Azman. Author. Zhian N. Kamvar. Contributor. Hugo Gruson. Contributor.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reich NG, Lessler J, Cummings DAT, Brookmeyer R. (2009). Estimating incubation periods coarse data. Statistics Medicine. 28(22):2769--2784. Reich NG, Lessler J, Cummings DAT, Brookmeyer R. Estimating absolute relative case fatality ratios infectious disease surveillance data. Biometrics. 2012, 68(2): 598--606. Reich NG, Lessler J, Azman . (2023). coarseDataTools: collection functions help analysis coarsely observed data. <https://cran.r-project.org/package=coarseDataTools, http://nickreich.github.io/coarseDataTools/>. R package version 0.7.1.","code":"@Article{,   title = {Estimating incubation periods with coarse data.},   author = {Nicholas G Reich and Justin Lessler and Derek AT Cummings and Ron Brookmeyer},   journal = {Statistics in Medicine},   year = {2009}, } @Article{,   title = {Estimating absolute and relative case fatality ratios from infectious disease surveillance data.},   author = {Nicholas G Reich and Justin Lessler and Derek AT Cummings and Ron Brookmeyer},   journal = {Biometrics},   year = {2012}, } @Manual{,   title = {coarseDataTools: A collection of functions to help with analysis of coarsely observed data},   author = {Nicholas G Reich and Justin Lessler and Andrew S Azman},   year = {2023},   note = {R package version 0.7.1},   url = {https://cran.r-project.org/package=coarseDataTools, http://nickreich.github.io/coarseDataTools/}, }"},{"path":"http://nickreich.github.io/coarseDataTools/index.html","id":"coarsedatatools","dir":"","previous_headings":"","what":"Analysis of Coarsely Observed Data","title":"Analysis of Coarsely Observed Data","text":"repository coarseDataTools R package. use development space. recent, stable version package can downloaded either CRAN (https://cran.r-project.org/package=coarseDataTools) recent release version github (https://github.com/nickreich/coarseDataTools/releases). package contains functions analyze coarsely observed data. Specifically, contains functions (1) fit parametric accelerated failure time models interval-censored survival time data, (2) estimate case-fatality ratio scenarios underreporting. package’s development motivated applications infectious disease: particular, problems estimating incubation period case fatality ratio given disease. Sample data files included package. March 2016, coarseDataTools imports functions MCMCpack package, turn imports functions graph Rgraphviz packages. packages removed CRAN, can installed Bioconductor using following code:","code":"source(\"https://bioconductor.org/biocLite.R\") biocLite(\"graph\") biocLite(\"Rgraphviz\")"},{"path":"http://nickreich.github.io/coarseDataTools/reference/EMforCFR.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to estimate the relative case fatality ratio when reporting rates\nare time-varying and deaths are lagged because of survival time. — EMforCFR","title":"A function to estimate the relative case fatality ratio when reporting rates\nare time-varying and deaths are lagged because of survival time. — EMforCFR","text":"function implements EM algorithm estimate relative case fatality ratio two groups reporting rates time-varying deaths lagged survival time.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/EMforCFR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to estimate the relative case fatality ratio when reporting rates\nare time-varying and deaths are lagged because of survival time. — EMforCFR","text":"","code":"EMforCFR(assumed.nu, alpha.start.values, full.data, max.iter = 50,   verb = FALSE, tol = 1e-10, SEM.var = TRUE)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/EMforCFR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to estimate the relative case fatality ratio when reporting rates\nare time-varying and deaths are lagged because of survival time. — EMforCFR","text":"assumed.nu vector probabilities corresponding survival distribution, .e. nu[]=Pr(surviving days | fatal case) alpha.start.values vector starting values reporting rate parameter GLM model. must length corresponds one less number unique integer values full.dat[,\"new.times\"]. full.data matrix observed data. See description . max.iter maximum number iterations EM algorithm accompanying SEM algorithm (used). verb indicator whether function print results runs. tol tolerance use test convergence EM algorithm. SEM.var TRUE, SEM algorithm run addition EM algorithm calculate variance parameter estimates.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/EMforCFR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to estimate the relative case fatality ratio when reporting rates\nare time-varying and deaths are lagged because of survival time. — EMforCFR","text":"list following elements naive.rel.cfr naive estimate relative case fatality ratio glm.rel.cfr reporting-rate-adjusted estimate relative   case fatality ratio EM.rel.cfr lag-adjusted estimate   relative case fatality ratio EM.re.cfr.var variance   log-scale lag-adjusted estimator taken final M-step EM.rel.cfr.var.SEM Supplemented EM algorithm variance   log-scale lag-adjusted estimator EM.rel.cfr.chain vector   EM algorithm iterates lag-adjusted relative CFR estimates EMiter number iterations needed EM algorithm   converge EMconv indicator convergence EM algorithm.  0   indicates parameters converged within max.iter iterations.  1 indicates   estimate relative case fatality ratio converged   .  2 indicates relative case fatality ratio   converge. SEMconv indicator convergence SEM algorithm.   scheme EMconv. ests coefficient estimates   model ests.chain matrix coefficient estimates,   EM iteration DM DM matrix SEM algorithm DMiter vector showing many iterations took   variance component converge SEM algorithm","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/EMforCFR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A function to estimate the relative case fatality ratio when reporting rates\nare time-varying and deaths are lagged because of survival time. — EMforCFR","text":"data matrix full.data must following columns: grp 1 2 indicating two groups, j,   observation . new.times integer value representing   time, t, observation. R count recovered cases   onset time t group j. D count deaths occurred   time t groupo j (note deaths disease onset   time t rather died time t). N total cases t, j,   sum R D columns.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/EMforCFR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function to estimate the relative case fatality ratio when reporting rates\nare time-varying and deaths are lagged because of survival time. — EMforCFR","text":"","code":"## This is code from the CFR vignette provided in the documentation.  data(simulated.outbreak.deaths) min.cases <- 10 N.1 <- simulated.outbreak.deaths[1:60, \"N\"] N.2 <- simulated.outbreak.deaths[61:120, \"N\"] first.t <- min(which(N.1 > min.cases & N.2 > min.cases)) last.t <- max(which(N.1 > min.cases & N.2 > min.cases)) idx.for.Estep <- first.t:last.t new.times <- 1:length(idx.for.Estep) simulated.outbreak.deaths <- cbind(simulated.outbreak.deaths, new.times = NA) simulated.outbreak.deaths[c(idx.for.Estep, idx.for.Estep + 60), \"new.times\"] <- rep(new.times, + 2) assumed.nu = c(0, 0.3, 0.4, 0.3) alpha.start <- rep(0, 22)  ## caution! this next line may take several minutes (5-10, depanding on ##    the speed of your machine) to run. if (FALSE) cfr.ests <- EMforCFR(assumed.nu = assumed.nu,                               alpha.start.values = alpha.start,                               full.data = simulated.outbreak.deaths,                               verb = FALSE,                               SEM.var = TRUE,                               max.iter = 500,                               tol = 1e-05)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/cd.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"An S4 Class that stores a fitted coarse data object — cd.fit","title":"An S4 Class that stores a fitted coarse data object — cd.fit","text":"output dic.fit(), contains important bits information model fit key options used.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/cd.fit.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"An S4 Class that stores a fitted coarse data object — cd.fit","text":"ests: Matrix class \"numeric\". matrix summarizes results fitting model. Rows correspond first parameter , second parameter percentiles specified ptiles argument. Columns correspond point estimate, lower upper bounds 95% confidence interval standard error point estimate. maximization converge, matrix filled NAs. conv: Object class \"numeric\". value 1 indicates successful convergence; 0 indicates unsuccessful convergence. MSG: Object class \"character\". error message returned optim() routine fails converge. loglik: Object class \"numeric\". Value estimated maximum log-likelihood. samples: Object class \"data.frame\". Data frame bootstrap estimates parameters (bootstraps performed). data: Object class \"data.frame\". Original data used fit model. dist: Object class \"character\". Failure time distribution fit data. \"L\" log-normal, \"G\" gamma, \"W\" Weibull, \"E\" Erlang. inv.hessian: Object class \"matrix\". inverse hessian matrix likelihood surface MLE. Used determine standard errors percentiles. Note optimization done transformed scale parameters logged distributions except first parameter log-normal distribution. est.method: Object class \"character\". Method used estimation. ci.method: Object class \"character\". Method used estimation confidence/credible intervals.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/cd.fit.mcmc.html","id":null,"dir":"Reference","previous_headings":"","what":"An S4 Class that stores a MCMC fit coarse data object — cd.fit.mcmc","title":"An S4 Class that stores a MCMC fit coarse data object — cd.fit.mcmc","text":"output dic.fit.mcmc(), contains important bits information model fit key options used.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/cd.fit.mcmc.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"An S4 Class that stores a MCMC fit coarse data object — cd.fit.mcmc","text":"ests: Matrix class \"numeric\". matrix summarizes results fitting model. Rows correspond first parameter , second parameter percentiles specified ptiles argument. Columns correspond point estimate, lower upper bounds 95% credible interval standard error point estimate. conv: Object class \"numeric\". used dic.fit.mcmc MSG: Object class \"character\". error message returned optim() routine fails converge. loglik: Object class \"numeric\".  used dic.fit.mcmc. samples: Object class \"data.frame\". Data frame posterior draws parameters. data: Object class \"data.frame\". Original data used fit model. dist: Object class \"character\". Failure time distribution fit data. \"L\" log-normal, \"G\" gamma, \"W\" Weibull, \"E\" Erlang. inv.hessian: Object class \"matrix\". used dic.fit.mcmc. est.method: Object class \"character\". Method used estimation. ci.method: Object class \"character\". Method used estimation confidence/credible intervals.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dgammaOff1.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that calculates dgamma with a offset of 1 (i.e., 1 is equivalent to 0) — dgammaOff1","title":"Function that calculates dgamma with a offset of 1 (i.e., 1 is equivalent to 0) — dgammaOff1","text":"Function calculates dgamma offset 1 (.e., 1 equivalent 0)","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dgammaOff1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that calculates dgamma with a offset of 1 (i.e., 1 is equivalent to 0) — dgammaOff1","text":"","code":"dgammaOff1(x, replace0 = FALSE, ...)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/dgammaOff1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that calculates dgamma with a offset of 1 (i.e., 1 is equivalent to 0) — dgammaOff1","text":"x value calculate dgamma replace0 replace 0 epsilon ... parameters dgamma","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dgammaOff1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that calculates dgamma with a offset of 1 (i.e., 1 is equivalent to 0) — dgammaOff1","text":"dgamma offset","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"censored survival data — dic.fit","title":"censored survival data — dic.fit","text":"dic.fit fits parametric accelerated failure time model survival data. developed application estimating incubation periods infectious diseases mind applicable many general problems. data can mixture doubly interval-censored, single interval-censored exact observations single univariate distribution. Currently, three distributions supported: log-normal, gamma, Weibull. (Erlang distribution supported dic.fit.mcmc function, implements MCMC version code.) use consistent (par1, par2) notation distribution, map following manner: $$Log-normal(meanlog=par1, sdlog=par2)$$ $$Gamma(shape=par1, scale=par2)$$ $$Weibull(shape=par1, scale=par2)$$ Standard errors parameters can computed using closed-form asymptotic formulae using bootstrap routine log-normal gamma models. Currently, bootstrap SEs option gamma models, closed form percentiles. dic.fit() calculates asymptotic SEs default, whenever n.boots option set 0. compute bootstrap SEs, just set n.boots greater zero. dic.fit.mcmc also allows Markov Chain Monte Carlo fitting three parametric models Erlang models well.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"censored survival data — dic.fit","text":"","code":"dic.fit(   dat,   start.par2 = log(2),   opt.method = \"L-BFGS-B\",   par1.int = log(c(0.5, 13)),   par2.int = log(c(1.01, log(5))),   ptiles = c(0.05, 0.95, 0.99),   dist = \"L\",   n.boots = 0,   ... )"},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"censored survival data — dic.fit","text":"dat matrix columns named \"EL\", \"ER\", \"SL\", \"SR\", corresponding left (L) right (R) endpoints windows possible exposure (E) symptom onset (S). Also, \"type\" column must specified entries 0, 1, 2, corresponding doubly interval-censored, single interval-censored exact observations, respectively. start.par2 starting value 2nd parameter desired distribution opt.method method used optim par1.int log-scale interval possible median values (units observations dat).  Narrowing interval can help speed convergence algorithm, care must taken possible values excluded maximization return value endpoint interval. par2.int log-scale interval possible dispersion values ptiles percentiles interest dist distribution use fit data. Default \"L\" log-normal. \"G\" gamma, \"W\" Weibull. n.boots number bootstrap resamples (0 means asymptotic results desired) ... additional options passed optim","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"censored survival data — dic.fit","text":"cd.fit S4 object.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"censored survival data — dic.fit","text":"Reich NG et al.  Statistics Medicine.  Estimating incubation   periods coarse data. 2009.   https://pubmed.ncbi.nlm.nih.gov/19598148/","code":""},{"path":[]},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"censored survival data — dic.fit","text":"","code":"data(fluA.inc.per) dic.fit(fluA.inc.per, dist=\"L\") #> Computing Asymptotic Confidence Intervals  #> Coarse Data Model Parameter and Quantile Estimates:  #>           est CIlow CIhigh StdErr #> meanlog 0.380 0.306  0.454  0.037 #> sdlog   0.424 0.368  0.480  0.028 #> p5      0.728 0.639  0.816  0.045 #> p50     1.462 1.354  1.570  0.055 #> p95     2.936 2.598  3.274  0.171 #> p99     3.919 3.344  4.494  0.291 #>  #> -2*Log Likelihood = 524.4  #>  #> Note: dispersion parameter is exp(sdlog). In this case it is 1.528 (95% CI 1.442-1.614)."},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.mcmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits the distribution to the passed-in data using MCMC\nas implemented in MCMCpack. — dic.fit.mcmc","title":"Fits the distribution to the passed-in data using MCMC\nas implemented in MCMCpack. — dic.fit.mcmc","text":"Similar dic.fit uses MCMC instead direct likelihood optimization routine fit model. Currently, four distributions supported: log-normal, gamma, Weibull, Erlang. See Details prior specification.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.mcmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits the distribution to the passed-in data using MCMC\nas implemented in MCMCpack. — dic.fit.mcmc","text":"","code":"dic.fit.mcmc(   dat,   prior.par1 = NULL,   prior.par2 = NULL,   init.pars = c(1, 1),   ptiles = c(0.05, 0.95, 0.99),   verbose = 1000,   burnin = 3000,   n.samples = 5000,   dist = \"L\",   seed = NULL,   ... )"},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.mcmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits the distribution to the passed-in data using MCMC\nas implemented in MCMCpack. — dic.fit.mcmc","text":"dat data prior.par1 vector first prior parameters model parameter. NULL default parameters used (described Details section). prior.par2 vector second prior parameters model parameter. NULL default parameters used (described Details section). init.pars initial parameter values (vector length = 2 ) ptiles returned percentiles survival survival distribution verbose often want print MCMCpack iteration number M-H acceptance rate burnin number burnin samples n.samples number samples draw posterior (burnin) dist distribution used (L log-normal,W weibull, G Gamma, E erlang, off1G 1 day right shifted gamma) seed seed random number generator MCMC ... additional parameters MCMCmetrop1R","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.mcmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits the distribution to the passed-in data using MCMC\nas implemented in MCMCpack. — dic.fit.mcmc","text":"cd.fit.mcmc S4 object","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/dic.fit.mcmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fits the distribution to the passed-in data using MCMC\nas implemented in MCMCpack. — dic.fit.mcmc","text":"following models used: $$Log-normal model: f(x) = \\frac{1}{x*\\sigma \\sqrt{2 * \\pi}} exp\\{-\\frac{(\\log x - \\mu)^2}{2 * \\sigma^2}\\}$$ $$Log-normal Default Prior: \\mu ~ N(0, 1000), log(\\sigma) ~ N(0,1000)$$ $$Weibull model: f(x) = \\frac{\\alpha}{\\beta}(\\frac{x}{\\beta})^{\\alpha-1} exp\\{-(\\frac{x}{\\beta})^{\\alpha}\\}$$ $$Weibull Default Prior Specification: log(\\alpha) ~ N( 0, 1000), \\beta ~ Gamma(0.001,0.001)$$ $$Gamma model: f(x) = \\frac{1}{\\theta^k \\Gamma(k)} x^{k-1} exp\\{-\\frac{x}{\\theta}\\}$$ $$Gamma Default Prior Specification: p(k,\\theta) \\propto \\frac{1}{\\theta} * \\sqrt{k*TriGamma(k)-1}$$ (Note: Jeffery's Prior parameters unknown), $$Trigamma(x) = \\frac{\\partial}{\\partial x^2} ln(\\Gamma(x))$$.) $$Erlang model: f(x) = \\frac{1}{\\theta^k (k-1)!} x^{k-1} exp\\{-\\frac{x}{\\theta}\\}$$ $$Erlang Default Prior Specification: k \\sim NBinom(100,1), log(\\theta) \\sim N(0,1000)$$ (Note: parameters negative binomial distribution represent mean size, respectively)","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/exp.win.lengths.html","id":null,"dir":"Reference","previous_headings":"","what":"Exposure window lengths from an influenza outbreak at a NYC school — exp.win.lengths","title":"Exposure window lengths from an influenza outbreak at a NYC school — exp.win.lengths","text":"numeric vector exposure window lengths taken dataset doubly interval-censored incubation period observations.  observations came NYC public school.  outbreak described full Lessler et al. (see citation ).","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/exp.win.lengths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exposure window lengths from an influenza outbreak at a NYC school — exp.win.lengths","text":"","code":"data(exp.win.lengths)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/exp.win.lengths.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Exposure window lengths from an influenza outbreak at a NYC school — exp.win.lengths","text":"numeric vector 134 positive values.  value represents exposure window length observation incubation period individual.  exposure window length length time exposure occurred.  example, individual exposed anytime 6am Monday 6am Wednesday, exposure window length 2 days.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/exp.win.lengths.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Exposure window lengths from an influenza outbreak at a NYC school — exp.win.lengths","text":"Lessler J et al.  New England Journal Medicine. Outbreak 2009 Pandemic Influenza (H1N1) New York City School. 2009. 361(27):2628-2636. https://www.nejm.org/doi/full/10.1056/nejmoa0906089","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/exp.win.lengths.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exposure window lengths from an influenza outbreak at a NYC school — exp.win.lengths","text":"","code":"data(exp.win.lengths) summary(exp.win.lengths) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.000   3.750   3.750   4.269   4.750  11.750  hist(exp.win.lengths)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/fluA.inc.per.html","id":null,"dir":"Reference","previous_headings":"","what":"Coarse incubation period data for influenza A — fluA.inc.per","title":"Coarse incubation period data for influenza A — fluA.inc.per","text":"observations incubation period influenza come variety sources, gathered literature review.  report doubly interval-censored, single interval-censored exact observations incubation period.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/fluA.inc.per.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coarse incubation period data for influenza A — fluA.inc.per","text":"","code":"data(fluA.inc.per)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/fluA.inc.per.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Coarse incubation period data for influenza A — fluA.inc.per","text":"data frame 151 observations following 7 variables. author name primary author source observation year year study source observation EL earliest possible time infection ER latest possible time infection SL earliest possible time symptom onset SR latest possible time symptom onset type indicator type observation: 0 doubly interval-censored, 1 single-interval censored, 2 exact","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/fluA.inc.per.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Coarse incubation period data for influenza A — fluA.inc.per","text":"Lessler J, Reich NG, Brookmeyer R, Perl TM, Nelson KE, Cummings DAT. (2009) systematic review incubation periods acute respiratory viral infections. Lancet Infectious Diseases. 9(5):291-300.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/fluA.inc.per.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coarse incubation period data for influenza A — fluA.inc.per","text":"","code":"data(fluA.inc.per) head(fluA.inc.per) #>   author year EL  ER  SL  SR type #> 1  moser 1977  0 0.5 1.0 1.5    0 #> 2  moser 1977  0 0.5 1.5 2.0    0 #> 3  moser 1977  0 0.5 1.5 2.0    0 #> 4  moser 1977  0 0.5 1.5 2.0    0 #> 5  moser 1977  0 0.5 1.5 2.0    0 #> 6  moser 1977  0 0.5 1.5 2.0    0"},{"path":"http://nickreich.github.io/coarseDataTools/reference/get.obs.type.html","id":null,"dir":"Reference","previous_headings":"","what":"Tries to guess the observation types (SIC, DIC, or exact). — get.obs.type","title":"Tries to guess the observation types (SIC, DIC, or exact). — get.obs.type","text":"Tries guess observation types (SIC, DIC, exact).","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/get.obs.type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tries to guess the observation types (SIC, DIC, or exact). — get.obs.type","text":"","code":"get.obs.type(dat)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/get.obs.type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tries to guess the observation types (SIC, DIC, or exact). — get.obs.type","text":"dat matrix data, similar needs passed dic.fit().","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/get.obs.type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tries to guess the observation types (SIC, DIC, or exact). — get.obs.type","text":"vector guessed types","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/logLik-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the log-likelihood value of a cd.fit or cd.fit.mcmc object — logLik,cd.fit-method","title":"Get the log-likelihood value of a cd.fit or cd.fit.mcmc object — logLik,cd.fit-method","text":"Get log-likelihood value cd.fit cd.fit.mcmc object","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/logLik-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the log-likelihood value of a cd.fit or cd.fit.mcmc object — logLik,cd.fit-method","text":"","code":"# S4 method for cd.fit logLik(object)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/logLik-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the log-likelihood value of a cd.fit or cd.fit.mcmc object — logLik,cd.fit-method","text":"object cd.fit cd.fit.mcmc object.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/logLik-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the log-likelihood value of a cd.fit or cd.fit.mcmc object — logLik,cd.fit-method","text":"log-likelihood value","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/loglikhd.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative log likelihood for a dataset of interval-censored data, given a\ndistribution and its parameters. — loglikhd","title":"Negative log likelihood for a dataset of interval-censored data, given a\ndistribution and its parameters. — loglikhd","text":"Negative log likelihood dataset interval-censored data, given distribution parameters.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/loglikhd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative log likelihood for a dataset of interval-censored data, given a\ndistribution and its parameters. — loglikhd","text":"","code":"loglikhd(pars, dat, dist)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/loglikhd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative log likelihood for a dataset of interval-censored data, given a\ndistribution and its parameters. — loglikhd","text":"pars vector transformed (estimation scale) parameters dat dataset, dic.fit dist distribution, dic.fit","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/loglikhd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative log likelihood for a dataset of interval-censored data, given a\ndistribution and its parameters. — loglikhd","text":"negative log-likelihood given dataset, parameters,   distribution.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/loglikhd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative log likelihood for a dataset of interval-censored data, given a\ndistribution and its parameters. — loglikhd","text":"package uses two versions parameter, estimation   scale, scale used numerical optimization,   reporting scale, natural scale parameters.   likelihood calculations, loglikhd function expects parameters   estimation scale, .e. range \\((-\\infty, \\infty)\\).   Specifically, translates parameters distributions   log-transformed except meanlog (.e. \"par1\")   log-normal distribution.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/mcmc.erlang.html","id":null,"dir":"Reference","previous_headings":"","what":"Does a metropolis hastings for the Erlang distribution — mcmc.erlang","title":"Does a metropolis hastings for the Erlang distribution — mcmc.erlang","text":"metropolis hastings Erlang distribution","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/mcmc.erlang.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Does a metropolis hastings for the Erlang distribution — mcmc.erlang","text":"","code":"mcmc.erlang(   dat,   prior.par1,   prior.par2,   init.pars,   verbose,   burnin,   n.samples,   sds = c(1, 1) )"},{"path":"http://nickreich.github.io/coarseDataTools/reference/mcmc.erlang.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Does a metropolis hastings for the Erlang distribution — mcmc.erlang","text":"dat data fit prior.par1 mean priors. negative binomial (shape) normal log(scale) prior.par2 dispersion parameters priors, dispersion negative binomial, log scale sd normal init.pars starting parameters reporting scale verbose often print update burnin many burnin iterations n.samples number samples keep report back sds standard deviations proposal distribution","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/mcmc.erlang.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Does a metropolis hastings for the Erlang distribution — mcmc.erlang","text":"matrix n.samples X 2 parameters, estimation scale","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/mcmcpack.ll.html","id":null,"dir":"Reference","previous_headings":"","what":"posterior log likelihood function to pass to MCMCpack sampler — mcmcpack.ll","title":"posterior log likelihood function to pass to MCMCpack sampler — mcmcpack.ll","text":"posterior log likelihood function pass MCMCpack sampler","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/mcmcpack.ll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"posterior log likelihood function to pass to MCMCpack sampler — mcmcpack.ll","text":"","code":"mcmcpack.ll(pars, dat, prior.par1, prior.par2, dist)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/mcmcpack.ll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"posterior log likelihood function to pass to MCMCpack sampler — mcmcpack.ll","text":"pars parameters calculate ll dat date base prior.par1 first parameter prior prior.par2 second parameter prior dist distribution likelihood calculated ","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/mcmcpack.ll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"posterior log likelihood function to pass to MCMCpack sampler — mcmcpack.ll","text":"posterior log likelihood","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/nycH1N1.html","id":null,"dir":"Reference","previous_headings":"","what":"Incubation period data from New York City Public Schools, 2009 H1N1 influenza outbreak — nycH1N1","title":"Incubation period data from New York City Public Schools, 2009 H1N1 influenza outbreak — nycH1N1","text":"observations incubation period influenza come investigation H1N1 outbreak NYC schools spring 2009. report doubly interval-censored observations incubation period.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/nycH1N1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Incubation period data from New York City Public Schools, 2009 H1N1 influenza outbreak — nycH1N1","text":"","code":"data(nycH1N1)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/nycH1N1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incubation period data from New York City Public Schools, 2009 H1N1 influenza outbreak — nycH1N1","text":"data frame 134 observations following 5 variables. EL earliest possible time infection ER latest possible time infection SL earliest possible time symptom onset SR latest possible time symptom onset type indicator type observation: 0 doubly interval-censored, 1 single-interval censored, 2 exact. observations doubly interval-censored.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/nycH1N1.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Incubation period data from New York City Public Schools, 2009 H1N1 influenza outbreak — nycH1N1","text":"Lessler J, Reich NG, Cummings DAT DOHMH Swine Influenza Investigation Team. Outbreak 2009 Pandemic Influenza (H1N1) New York City School. New England Journal Medicine. 2009. 361(27):2628-2636.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/nycH1N1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Incubation period data from New York City Public Schools, 2009 H1N1 influenza outbreak — nycH1N1","text":"","code":"data(nycH1N1) head(nycH1N1) #>     EL ER SL SR type #> 1 0.00 10  9 10    0 #> 2 7.25 11 10 11    0 #> 3 7.25 11 10 11    0 #> 4 7.25 11 10 11    0 #> 5 7.25  9  8  9    0 #> 6 7.25 10  9 10    0 if (FALSE) dic.fit(nycH1N1)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/pgammaOff1.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that calculates pgamma with a offset of 1 (i.e., 1 is equivalent to 0) — pgammaOff1","title":"Function that calculates pgamma with a offset of 1 (i.e., 1 is equivalent to 0) — pgammaOff1","text":"Function calculates pgamma offset 1 (.e., 1 equivalent 0)","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/pgammaOff1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that calculates pgamma with a offset of 1 (i.e., 1 is equivalent to 0) — pgammaOff1","text":"","code":"pgammaOff1(x, replace0 = FALSE, ...)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/pgammaOff1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that calculates pgamma with a offset of 1 (i.e., 1 is equivalent to 0) — pgammaOff1","text":"x value calculate pgamma replace0 replace 0 epsilon ... parameters pgamma","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/pgammaOff1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that calculates pgamma with a offset of 1 (i.e., 1 is equivalent to 0) — pgammaOff1","text":"pgamma offset","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/precision.simulation.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate incubation period analyses with coarse data — precision.simulation","title":"Simulate incubation period analyses with coarse data — precision.simulation","text":"functions simulate coarse incubation period data sets   analyze .  goal simulations provide evidence   much information given dataset contains characteristic   incubation period distribution.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/precision.simulation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate incubation period analyses with coarse data — precision.simulation","text":"","code":"precision.simulation(   N,   med = 2,   disp = 1.3,   percentile = 0.5,   nsim = 100,   exact.data = FALSE,   pct.type.A = 0.5,   exp.win.dat = NULL,   verb = FALSE )  precision.simulation.exact(N, med, disp, percentile, nsim, verb)  precision.simulation.coarse(   N,   med,   disp,   percentile,   nsim,   pct.type.A,   exp.win.dat,   verb )  generate.coarse.data(N, med, disp, pct.type.A, exp.win.dat)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/precision.simulation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate incubation period analyses with coarse data — precision.simulation","text":"N Overall sample size datasets simulated. med Median assumed log normal distribution incubation periods. disp Dispersion assumed log normal distribution incubation periods. percentile Percentile incubation period distribution want estimate. nsim Number datasets analyze simulation. exact.data Either TRUE/FALSE.  Incidates whether data generated coarsened .  TRUE, pct.type.exp.win.dat ignored. pct.type.Percent N observations assumed type data.  N*pct.type.integer, rounded nearest integer. exp.win.dat vector exposure window lengths.  Defaults observed window lengths Lessler et al. (see ). verb TRUE, message system time iteration number printed ten times simulation run.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/precision.simulation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate incubation period analyses with coarse data — precision.simulation","text":"precision.simulation functions return matrix four   columns nsim rows.  \"ests\" column gives estimated percentiles   incubation period distribution.  \"SE\" column gives   standard error estimate.  \"conv\" column 1 doubly   interval-censored likelihood maximization converged.  Otherwise, 0.   \"bias\" column gives estimated percentile - true percentile.  generate.coarse.data function returns matrix data suitable   analysis dic.fit function.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/simulated.outbreak.deaths.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated case and death reports from a fictional outbreak — simulated.outbreak.deaths","title":"Simulated case and death reports from a fictional outbreak — simulated.outbreak.deaths","text":"dataset provides reported counts cases deaths occurring different time points across simulated outbreak. Details data simulation algorithm provided manuscript \"Estimating case fatality ratios infectious disease surveillance data\" (Reich et al., review, available upon request).","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/simulated.outbreak.deaths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated case and death reports from a fictional outbreak — simulated.outbreak.deaths","text":"","code":"data(simulated.outbreak.deaths)"},{"path":"http://nickreich.github.io/coarseDataTools/reference/simulated.outbreak.deaths.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated case and death reports from a fictional outbreak — simulated.outbreak.deaths","text":"time time, t,  start outbreak grp categorical variable indicating membership one two groups covariate, j R number recovered cases reported given t j D number deaths reported given t j N total number cases deaths reported t j, D+R","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/simulated.outbreak.deaths.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated case and death reports from a fictional outbreak — simulated.outbreak.deaths","text":"Reich NG, Lessler J, Cummings DAT, Brookmeyer R. Estimating case fatality ratios infectious disease surveillance data. Biometrics. 2012. 68(2): 598-606.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/reference/simulated.outbreak.deaths.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated case and death reports from a fictional outbreak — simulated.outbreak.deaths","text":"","code":"data(simulated.outbreak.deaths) head(simulated.outbreak.deaths) #>   time grp R D N #> 1    1   1 0 0 0 #> 2    2   1 0 0 0 #> 3    3   1 0 0 0 #> 4    4   1 0 0 0 #> 5    5   1 0 0 0 #> 6    6   1 0 0 0 plot(simulated.outbreak.deaths[simulated.outbreak.deaths[,\"grp\"]==1,\"D\"], type=\"l\")"},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-071","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.7.1","title":"coarseDataTools 0.7.1","text":"Added pkgdown, moved ChangeLog NEWS.md","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-07","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.7","title":"coarseDataTools 0.7","text":"Refactor code align lintr standards, adding Hugo Gruson contributor.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-066","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.6.6","title":"coarseDataTools 0.6.6","text":"update vignette Rmd, removal plot method cd.fit object.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-065","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.6.5","title":"coarseDataTools 0.6.5","text":"minor modifications fix improper call class() new NOTES.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-064","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.6.4","title":"coarseDataTools 0.6.4","text":"merged hackout3 branch support new distributions","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-063","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.6.3","title":"coarseDataTools 0.6.3","text":"minor modifications address NAMESPACE issues.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-06","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.6","title":"coarseDataTools 0.6","text":"added Azman/Lessler contributions: MCMC estimation functions, ability fit Weibull Gamma distributions, bootstrap confidence intervals.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-051","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.5.1","title":"coarseDataTools 0.5.1","text":"CRAN release: 2012-10-29 changed code eliminate NOTE message R CMD CHECK.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-05","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.5","title":"coarseDataTools 0.5","text":"added get.obs.type() function easily generate observation types data set doubly interval censored format.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-04","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.4","title":"coarseDataTools 0.4","text":"added functions simulation precision estimated percentiles coarse incubation period datasets.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-03","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.3","title":"coarseDataTools 0.3","text":"CRAN release: 2010-08-18 added documentation datafiles.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-02","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.2","title":"coarseDataTools 0.2","text":"CRAN release: 2010-05-05 added functions (documentation) estimating univariate distribution arbitrary mixture doubly interval-censored, single interval-censored exact observations using maximum likelihood approach.","code":""},{"path":"http://nickreich.github.io/coarseDataTools/news/index.html","id":"coarsedatatools-01","dir":"Changelog","previous_headings":"","what":"coarseDataTools 0.1","title":"coarseDataTools 0.1","text":"CRAN release: 2010-04-09 added functions (documentation) estimating relative case fatality ratio. Currently tested situations two groups interest, .e. two levels covariate J.","code":""}]
